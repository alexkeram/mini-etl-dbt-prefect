    "# Teaching with a teacher - model quality\n",
    "## 📌 Project goal\n",
    "To develop a model that predicts the probability of reducing the customer’s purchasing activity, and highlight segments for personalized marketing offers.Link to the Hithab repository: https://github.com/alexkeram/teach-model\n",
    "## 🔹 Step 1. Data loading\n",
    "- Download all the files provided:\n",
    "- `/datasets/market_file.csv`\n",
    "- `/datasets/market_money.csv`\n",
    "- `/datasets/market_time.csv`\n",
    "- `/Datasets/money.csv`\n",
    "- Make sure that the data correspond to the description.\n",
    "- Check the separators and correctly consider the tables (special attention on `Sep = ';'` `and` decimal = ',' `).\n",
    "## 🔹 Step 2. Data value\n",
    "- Check data types, passes, duplicates.\n",
    "- Transform numerical signs into the correct format (for example, with `Object` →` float`).\n",
    "- Delete or fill out missing values.\n",
    "- Conduct primary cleaning and, if necessary, transcode categorical values.\n",
    "## 🔹 Step 3. Research Analysis of Data (EDA)\n",
    "- Conduct visualization and descriptive analysis of the signs:\n",
    "- Distributions,\n",
    "- emissions,\n",
    "- unique values ​​of categorical features.\n",
    "- identify customers having at least one purchase for the last 3 months.\n",
    "- Check the distribution of the target feature (`purchasing activity`).\n",
    "- identify potential correlations and anomalies.\n",
    "## 🔹 Step 4.\n",
    "- combine the tables by `id`, transforming:\n",
    "- `market_money.csv` in width for the periods:` revenue_ket`, `revenue_fire`,` revenue_d_ now.\n",
    "- `market_time.csv` in a similar width:` Time_ket`, `Time_field`,` Time_D_ This.\n",
    "- attach to `market_file.csv`.\n",
    "- Save the table `money.csv` with a profit separately (use later for segmentation).\n",
    "## 🔹 Step 5. Correlation analysis\n",
    "- Calculate the correlation matrix between numerical signs.\n",
    "- visualize the heat card.\n",
    "- if necessary - remove one of the strongly correlating signs (multicollinearity).\n",
    "## 🔹 Step 6. Building of models using soldiers\n",
    "### 6.1 Preparation of Paydain\n",
    "- Use `Columntransformer` for separate processing of signs:\n",
    "- Categorical: `ONEHOTENCODER`,` ORDINALENCODER`\n",
    "- Numerical: `StandardScaler`,` minmaxScaler`\n",
    "- Gather Piplaine based on `pipeline`.\n",
    "### 6.2 Model training\n",
    "Teach the following models with the selection of hyperparameters:\n",
    "- `logisticregression`\n",
    "- `decisiontreeclassifier`\n",
    "- `Kneighborsclassifier`\n",
    "- `svc`\n",
    "### 6.3 Selection of metric\n",
    "- The main metric: ** roc auc ** (due to the task of binary classification and possible imbalance of classes).\n",
    "- Use `RandomizedSearchcv` or` Gridsearchcv` with cross-native.\n",
    "## 🔹 Step 7. Model interpretation\n",
    "- Determine the best model by ROC AUC.\n",
    "- calculate the importance of signs for the best model.\n",
    "- Use the `Shap 'library to build a graph of importance.\n",
    "- Conclusion:\n",
    "- what signs have had the greatest influence;\n",
    "- which can be excluded;\n",
    "- Business interpretation of the result.\n",
    "## 🔹 Step 8. Customer segmentation and recommendations\n",
    "### 8.1 segmentation\n",
    "- combine these models (probabilities of reducing activity) and `money.csv`.\n",
    "- Create segments (approximately 2-3 segments) by:\n",
    "- profit,\n",
    "- share of promotional purchases,\n",
    "- Categories of goods,\n",
    "- probabilities of reducing activity.\n",
    "### 8.2 segment analysis\n",
    "- visualize the distributions and signs of the selected segment.\n",
    "- Describe business characteristics.\n",
    "- Make proposals to keep activity:\n",
    "- Changing the conditions of mailings,\n",
    "- New promotions,\n",
    "- personalized proposals.\n",
    "### 8.3 Cods on segments\n",
    "- What segment is chosen.\n",
    "- What measures are proposed.\n",
    "- Why is it important for business.\n",
    "## 🔹 Step 9. General conclusion\n",
    "\n",
    "- Briefly describe:\n",
    "- The task,\n",
    "- initial data and sources,\n",
    "- Stages of expense,\n",
    "- Model training and results,\n",
    "- the selected model and metric,\n",
    "- interpretation of signs,\n",
    "- segmentation and business recommendations.\n"
   ],
   "outputs": [],
   "execution_count": null
    "# General libraries\n",
    "Import Pandas as PD\n",
    "Import Numpy AS NP\n",
    "Import Math\n",
    "From Pathlib Import Path\n",
    "From Ipython.display Import Display\n",
    "# Visualization\n",
    "Import MatPlotlib.pyplot as PLT\n",
    "\n",
    "# Caluation\n",
    "from sklearn.model_selection Import Train_test_split\n",
    "From Sklearn.preProcessing Import StandardScaler, MinmaxScaler\n",
    "From Sklearn.preProcessing Import Onehotencoder\n",
    "From Sklearn.impute Import Simpleimputer\n",
    "From Sklearn.compose Import Columntransformer\n",
    "From Sklearn.pipeline Import Pipeline\n",
    "\n",
    "# Model\n",
    "from sklearn.linear_model Import Logisticregression\n",
    "From Sklearn.tree Import Decisiontreeclassifier\n",
    "From Sklearn.neighbors Import Kneighborsclassifier\n",
    "from sklearn.svm Import SVC\n",
    "\n",
    "# Selection of hyperparameters\n",
    "From Sklearn.model_Selection Import RandomizedSearchcv\n",
    "\n",
    "# Metrics\n",
    "ROC_AUC_SCORE,\n",
    "# Interpretation of signs\n",
    "Import Shap\n",
    "# Ignore warnings\n",
    "Import Warnings\n",
    "Warnings.FilterWarnings ('Ignore')\n",
    "# Settings for visualization\n",
    "plt.rcparams ['figure.figsize'] = (10, 6)\n",
    "TQDM.pandas (Disable = True)\n"
   "execution_count": null
    "# Step 1. Data loading\n",
    "\n",
    "# Paths to files\n",
    "\n",
    "# first try the old option\n",
    "if Path ('/Datasets/Market_file.csv'). Exists ():\n",
    "File_path_main = '/datasets/market_file.csv'\n",
    "File_path_money = '/datasets/market_money.csv'\n",
    "File_path_time = '/datasets/market_time.csv'\n",
    "File_path_profit = '/datasets/money.csv'\n",
    "Else:\n",
    "# Spare option\n",
    "File_path_main = 'Data/Market_file.csv'\n",
    "File_path_money = 'Data/Market_money.csv'\n",
    "File_path_time = 'Data/Market_time.csv'\n",
    "File_path_profit = 'Data/Money.csv'\n",
    "\n",
    "# Download the tables\n",
    "df_main = pd.read_csv (file_path_main, sp = ',', decimal = '.')\n",
    "df_revenue = pd.read_csv (file_path_money, sep = ',', decimal = '.')\n",
    "df_time = pd.read_csv (file_path_time, sep = ',', decimal = '.')\n",
    "df_profit = pd.read_csv (file_path_profit, sep = ';', decimal = ',')\n",
    "\n",
    "# View the first lines and information about tables\n",
    "Print (\"Market_file.csv:\")\n",
    "Display (df_main.head ())\n",
    "Print (df_main.info (), '\\ n')\n",
    "\n",
    "Print (\"Market_Money.csv:\")\n",
    "Display (df_revenue.head ())\n",
    "print (df_revenue.info (), '\\ n')\n",
    "\n",
    "Print (\"Market_time.csv:\")\n",
    "Display (df_time.head ())\n",
    "Print (df_time.info (), '\\ n')\n",
    "\n",
    "Print (\"Money.csv:\")\n",
    "Display (df_profit.head ())\n",
    "Print (df_profit.info ())\n"
   "outputs": [],
   "execution_count": null
    "### conclusion by step 1: Data loading\n",
    "The data are successfully loaded and generally correspond to the description.All tables have the correct structure and the required number of lines.The detected minor inconsistencies in individual values ​​(for example, typos in the names of categories or periods) will be processed in the corresponding sections of the exponent and data purification sections.You can proceed to the next stage.\n"
   ],
   "outputs": [],
   "execution_count": null
    "# Data reporting\n"
   ],
   "outputs": [],
   "execution_count": null
    "# Step 2. Data Assembly\n",
    "\n",
    "# Verification of data types, passes and duplicates in all tables\n",
    "\n",
    "Def Check_DF (DF, NAME):\n",
    "Print (f '\\ n ===== {name} =====')\n",
    "Print ('Form:', df.shape)\n",
    "print ('duplicates:', df.duplicated (). Sum ())\n",
    "Print ('Types of Data:')\n",
    "Print (df.dtypes)\n",
    "Print ('\\ nproducts by columns:')\n",
    "Print (df.isna (). Sum ())\n",
    "Print ('-' * 50)\n",
    "\n",
    "Check_DF (df_main, 'main table (market_file)')\n",
    "Check_DF (df_revenue, 'revenue (market_money)')\n",
    "Check_DF (df_time, 'time on the site (market_time)')\n",
    "Check_DF (df_profit, 'profit (money)')\n"
   "outputs": [],
   "execution_count": null
    "# Visualization of passes in the main table\n",
    "PLT.Figure (figsize = (10, 4))\n",
    "PLT.BAR (df_main.columns, df_main.isna (). Sum ())\n",
    "PLT.XTICS (Rotation = 90)\n",
    "plt.title ('venues in the main table')\n",
    "PLT.YLABEL ('number of passes')\n",
    "PLT.GRID (Axis = 'Y')\n",
    "plt.tight_layout ()\n",
    "PLT.SHOW ()\n"
   "outputs": [],
   "execution_count": null
    "# Transformation of types\n",
    "# We check if there are non -layered data in numerical columns (just in case)\n",
    "For color in df_main.select_dtypes (include = 'Object'). Columns:\n",
    "print (f '{color}: {df_main [color] .unique () [: 5]} ...') # the first 5 unique values\n"
   "outputs": [],
   "execution_count": null
    "# Delete duplicates, if any\n",
    "df_main = df_main.drop_duplicates ()\n",
    "df_revenue = df_revenue.drop_duplicates ()\n",
    "df_time = df_time.drop_duplicates ()\n",
    "df_profit = df_profit.drop_duplicates ()\n"
   "execution_count": null
    "# Correct the typo in \"Type of service\" (standard → standard)\n",
    "df_main ['Type of service'] = df_main ['type of service']. Replace ('standard', 'standard')\n",
    "# We correct the typo in the \"period\" in Market_time\n",
    "df_time ['period'] = df_time ['period']. Replace ({'previous_xyan': 'previous_ mixed'})\n"
   "execution_count": null
    "# Let us bring the values ​​in \"Allow\" to report \"to the binary form (yes → 1, no → 0)\n",
    "df_main ['allow reporting'] = df_main ['allow reporting']. Map ({'yes': 1, 'no': 0})\n"
   "execution_count": null
    "# Size check after cleaning\n",
    "Print (F'OSNENT TOME: {df_main.shape} ')\n",
    "Print (F'Bruchka: {df_revenue.shape} ')\n",
    "Print (F' -over on the site: {df_time.shape} ')\n",
    "Print (F'PILL: {df_profit.shape} ')\n"
   "outputs": [],
   "execution_count": null
    "# Let's look at the unique values ​​of categorical variables\n",
    "Cat_columns = ['Consumicular activity', 'Type of service', 'Popular_Category']\n",
    "for color in cat_columns:\n",
    "Print (f '\\ n {color}:')\n",
    "print (df_main [color] .value_counts ())\n"
   "outputs": [],
   "execution_count": null
    "# Build histograms for all numerical signs\n",
    "# Numerical signs\n",
    "num_columns = df_main.select_dtypes (include = ['int64', 'float64']). Columns\n",
    "# Parameters of the grid\n",
    "Cols = 3\n",
    "rows = math.ceil (len (num_columns) / cols)\n",
    "PLT.Figure (figsize = (5 * cols, 4 * rows))\n",
    "for i, color in enumerate (num_columns):\n",
    "PLT.SUBPLOT (Rows, Cols, I + 1)\n",
    "PLT.Hist (df_main [color], bins = 20, edgecolor = 'Black')\n",
    "plt.title (color)\n",
    "plt.tight_layout ()\n",
    "PLT.SUPTITLE ('Distribution of numerical features', y = 1.02, fontsize = 16)\n",
    "PLT.SHOW ()\n"
   "outputs": [],
   "execution_count": null
    "# Graphs of the distribution of categorical features\n",
    "PLT.Figure (figsize = (15, 6))\n",
    "for i, color in enumerate (cat_columns):\n",
    "PLT.SUBPLOT (1, 3, I+1)\n",
    "df_main [color] .value_counts (). Plot (kind = 'bar')\n",
    "plt.title (color)\n",
    "PLT.XTICS (Rotation = 45)\n",
    "plt.tight_layout ()\n",
    "PLT.SUPTITLE ('Distribution of categorical features', y = 1.05, fontsize = 16)\n",
    "PLT.SHOW ()\n"
   "outputs": [],
   "execution_count": null
    "# Check 1: Basic Dataset (should be 1 line per client)\n",
    "duplicate_main = df_main [df_main.duplicated (subset = 'id', keep = false)]\n",
    "Print (F'ping ID in Market_File: {Duplicate_main.shape [0]} ')\n",
    "Display (duplicate_main)\n",
    "# Check 2: revenue - implicit duplicates according to ID + period\n",
    "duplicate_revenue = df_revenue [df_revenue.duplicated (subset = ['id', 'period'], keep = false)]]\n",
    "Print (F'NEYAVE DUBITIONS in Market_Money according to (ID, period): {duplicate_revenue.shape [0]} ')\n",
    "Display (duplicate_revenue.sort_values ​​(by = ['id', 'period']))\n",
    "# Verification 3: Time - implicit duplicates according to ID + period\n",
    "duplicate_time = df_time [df_time.duplicated (subset = ['id', 'period'], keep = false)]]\n",
    "Print (F'NEYAVE DUBITIONS in Market_Time by (ID, period): {duplicate_time.shape [0]} ')\n",
    "Display (duplicate_time.sort_values ​​(by = ['id', 'period']))\n",
    "# Check 4: Profit table - there should be one ID per line\n",
    "duplicate_profit = df_profit [df_profit.duplicated (subset = 'id', keep = false)]]]]]]\n",
    "Print (F'PPOGEN ID in money.csv: {duplicate_profit.shape [0]} ')\n",
    "Display (duplicate_profit)\n"
   "outputs": [],
   "execution_count": null
    "## Analysis and removal of revenue emissions\n"
   ],
   "outputs": [],
   "execution_count": null
    "Purpose: to exclude customers with abnormally high revenue so that the model is not distorted by extreme values.\n"
   ],
   "outputs": [],
   "execution_count": null
    "#Parts for revenue\n",
    "PLT.Figure (figsize = (10, 1))\n",
    "PLT.BOXPLOT (df_revenue ['revenue'], vert = false)\n",
    "PLT.Title ('BOXPLOT RECOUNITIONS (Market_Money)')\n",
    "PLT.XLABEL ('revenue')\n",
    "PLT.GRID (True, Axis = 'X')\n",
    "PLT.SHOW ()\n"
   "outputs": [],
   "execution_count": null
    "We cut off the radical emission on top, without touching the smaller values\n"
   ],
   "outputs": [],
   "execution_count": null
    "# Calculation of borders by the method of inter -apartment scope\n",
    "Q1 = df_revenue ['revenue']. ​​Quantile (0.25)\n",
    "Q3 = df_revenue ['revenue']. ​​Quantile (0.75)\n",
    "Print (F' -border on the top: {upper_bound: .2f} ')\n",
    "# Filtering: Leave only reasonable revenue values\n",
    "df_revenue = df_revenue [df_revenue ['revenue'] <= upper_bound]\n"
   "outputs": [],
   "execution_count": null
    "#Parts for revenue\n",
    "PLT.Figure (figsize = (10, 1))\n",
    "PLT.BOXPLOT (df_revenue ['revenue'], vert = false)\n",
    "PLT.Title ('BOXPLOT RECOUNITIONS (Market_Money)')\n",
    "PLT.XLABEL ('revenue')\n",
    "PLT.GRID (True, Axis = 'X')\n",
    "PLT.SHOW ()\n"
   "outputs": [],
   "execution_count": null
    "## filtering inactive customers\n"
   ],
   "outputs": [],
   "execution_count": null
    "Target:\n",
    "Remove customers from analysis who did not buy anything in at least one month\n",
    "- We consider the total revenue for each ID.\n",
    "- We leave only those who had purchases\n",
    "- Find all the tables for these IDs.\n"
   ],
   "outputs": [],
   "execution_count": null
    "# We convert the table into a wide format\n",
    "Revenue_Raw = pd.read_csv ('Data/Market_money.csv')\n",
    "Revenue_pivot = revenue_Raw.pivot (index = 'id', columns = 'period', values ​​= 'revenue')\n",
    "# We will find customers who have at least one month = 0\n",
    "IDS_TO_REMOVE = revenue_pivot [revenue_pivot.isna (). Any (Axis = 1) |(Revenue_pivot == 0) .any (Axis = 1)]. index\n",
    "Print (F'udal of customers: {len (ids_to_remove)} - {list (ids_to_remove)} ')\n",
    "# Filter all tables\n",
    "df_main = df_main [~ df_main ['id']. Isin (ids_to_remove)]\n",
    "df_revenue = df_revenue [~ df_revenue ['id']. Isin (ids_to_remove)]\n",
    "df_time = df_time [~ df_time ['id']. Isin (ids_to_remove)]\n",
    "df_profit = df_profit [~ df_profit ['id']. Isin (ids_to_remove)]\n",
    "Print (F \"There are customers after filtration: {df_main ['id']. Nunique ()}\")\n"
   "outputs": [],
   "execution_count": null
    "### Conclusion by step 2: data reporting\n",
    "\n",
    "- ** Data types ** in all tables are given to the correct format, numerical and categorical features are recognized correctly.\n",
    "- ** Passes ** and**duplicates ** in the main table (`market_file.csv`) are absent.\n",
    "- were eliminated ** typos ** in the data: `` Standatt '→' Standard'`, `'' previous_ mixed '→' 'previous_xyats'``.\n",
    "- The meaning of the sign `Allocate to report` is given to the binary format:` yes` → `1`,` no` → `0`.\n",
    "- The target feature of `Consumeric activity` contains two classes with moderate imbalance and is ready for binary encoding.\n",
    "- Categorical features (`Service type,` Popular category`) have an adequate distribution and are prepared for subsequent coding.\n",
    "- With a clock, numerical signs do not contain obvious emissions, except for one radical emission in the table with the revenue that was filtered, the majority are distributed normally or discretely.\n",
    "- In the tables `market_money` and` market_time` did not reveal duplicate duplicates according to the composition of the composition of `id + period`.\n",
    "- In the `money.csv` table, each` id` is once found, the structure is correct.\n"
   ],
   "outputs": [],
   "execution_count": null
    "# Research Data Analysis (EDA)\n"
   ],
   "outputs": [],
   "execution_count": null
    "# We build the distribution of the target feature\n",
    "PLT.Figure (figsize = (6, 4))\n",
    "df_main ['purchasing activity']. Value_counts (). Plot (kind = 'bar')\n",
    "PLT.Title ('distribution of purchasing activity among active customers')\n",
    "PLT.YLABEL ('number of customers')\n",
    "PLT.XTICS (Rotation = 0)\n",
    "plt.tight_layout ()\n",
    "PLT.SHOW ()\n",
    "\n",
    "# percent\n",
    "print (df_main ['purchasing activity']. Value_counts (normalize = true) * 100, 2))\n"
   "outputs": [],
   "execution_count": null
    "# We leave only numerical features\n",
    "numeric_features = df_main.drop (columns = ['id', 'purchasing activity']). Select_dtypes (include = ['int64', 'float64'])\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "Corr = numeric_features.corr (Method = 'Spearman')\n",
    "\n",
    "# Building a heat card\n",
    "PLT.Figure (figsize = (12, 10))\n",
    "IM = PLT.IMSHOW (Corr, CMAP = 'RdyLGN', VMIN = -1, VMAX = 1)\n",
    "\n",
    "# Signatures of the axes\n",
    "PLT.XTICS (Ticks = NP.ARANGE (LEN (Corr.columns)), Labels = Corr.columns, Rotation = 90)\n",
    "PLT.YTICS (Ticks = NP.ARANGE (LEN (Corr.index)), Labels = Corr.index)\n",
    "\n",
    "# Adding values ​​to a thermal card\n",
    "For i in Range (Len (Corr.index)):\n",
    "for j in range (Len (Corr.columns)):\n",
    "PLT.TEXT (J, I, F \"{Corr.iloc [i, J] :.2F}\",\n",
    "Ha = \"Center\", va = \"center\", color = \"Black\", fontsize = 8)\n",
    "\n",
    "# Color scale\n",
    "PLT.colorbar (IM)\n",
    "plt.title ('correlation matrix of numerical signs')\n",
    "plt.tight_layout ()\n",
    "PLT.SHOW ()\n"
   "outputs": [],
   "execution_count": null
    "# List of numerical features, excluding ID\n",
    "num_cols = df_main.select_dtypes (include = ['int64', 'float64']). Drop (Columns = 'Id'). Columns).\n",
    "# Create a summary summary\n",
    "for color in num_cols:\n",
    "q1 = df_main [color] .quantile (0.25)\n",
    "q3 = df_main [color] .quantile (0.75)\n",
    "IQR = Q3 - Q1\n",
    "Lower = Q1 - 1.5 * IQR\n",
    "UPPER = Q3 + 1.5 * IQR\n",
    "outliers = df_main [(df_main [color] <lower) |(df_main [color]> upper)]\n",
    "outliers_summary [color] = len (outliers)\n",
    "\n",
    "# Conclusion of the number of emissions for each basis\n",
    "for color, Count in Outliers_summary.items ():\n",
    "print (f '{color}: {count} emissions')\n"
   "outputs": [],
   "execution_count": null
    "# Visualization of emissions\n",
    "Cols = 3\n",
    "rows = (Len (num_cols) + cols - 1) // Cols\n",
    "PLT.Figure (figsize = (5 * cols, 4 * rows))\n",
    "for i, color in enumerate (num_cols):\n",
    "PLT.SUBPLOT (Rows, Cols, I + 1)\n",
    "PLT.BOXPLOT (df_main [color], Vert = false)\n",
    "plt.title (color)\n",
    "PLT.SUPTITLE ('BOXPLOT for numerical signs', fontsize = 16, y = 1.02)\n",
    "plt.tight_layout ()\n",
    "PLT.SHOW ()\n"
   "outputs": [],
   "execution_count": null
    "# Counting the number of customers by categories\n",
    "Activity_counts = df_main ['purchasing activity']. Value_counts ()\n",
    "Activity_labels = Activity_counts.index\n",
    "Activity_values ​​= Activity_counts.values\n",
    "# Building a graph\n",
    "PLT.Figure (figsize = (6, 4))\n",
    "Bars = PLT.BAR (Activity_Labels, Activity_values, Color = ['#4Caf50', '#F44336'])\n",
    "# Add annotations over column\n",
    "Height = bar.get_height ()\n",
    "PLT.TEXT (bar.get_x () + bar.get_width () / 2, height + 10, f '{height}', ha = 'centom')\n",
    "\n",
    "plt.title ('number of clients by activity')\n",
    "PLT.YLABEL ('number of customers')\n",
    "PLT.XTICS (Rotation = 0)\n",
    "PLT.GRID (Axis = 'Y', linestyle = '-', alpha = 0.5)\n",
    "plt.tight_layout ()\n",
    "PLT.SHOW ()\n",
    "Print (F'kolism of active customers: {df_main.shape [0]} ')\n"
   "outputs": [],
   "execution_count": null
    "### conclusion by step 3: Research analysis of data\n",
    "\n",
    "- Clients with purchases: 1297 had revenue in each month of the period.\n",
    "- Most customers (802) remained active, 495 - reduced activity.\n",
    "- The target feature: ~ 61.7% of customers retained the previous level of activity, ~ 38.3% - reduced.The classes are modeled moderately.\n",
    "- Correlations:\n",
    "- There were no strong multi - - - -halinearity between the signs.\n",
    "- The most pronounced positive correlations were revealed between signs of behavior on the site: `pages_za_vizit`,` average_ -recruiting_Kategoria_za_zit`, `Duration`.\n",
    "- emissions:\n",
    "- the largest number of emissions according to the signs of `Market_activ_tex_,` Active_Carus`, `unpaid_products_Stuk_Cartal`.\n",
    "- emissions are preserved as a potentially significant part of client behavior.\n"
   ],
   "outputs": [],
   "execution_count": null
    "# Tables Association\n"
   ],
   "outputs": [],
   "execution_count": null
    "# Turn revenue\n",
    "df_revenue_wide = df_revenue.pivot (index = 'id', columns = 'period', values ​​= 'revenue'). Reset_index ()\n",
    "df_revenue_wide.columns.name = none # Remove the name of the column level\n",
    "df_revenue_wide = df_revenue_wide.rename (columns = {\n",
    "'current_xyats': 'revenue_tea',\n",
    "'Previous_xyats': 'revenue_ predecessor',\n",
    "'Perebuskeeping_xyas': 'revenue_ -reimbursable'\n",
    "# Time rotation\n",
    "df_time_wide = df_time.pivot (index = 'id', columns = 'period', values ​​= 'minutes'). Reset_index ()\n",
    "df_time_wide.columns.name = none\n",
    "df_time_wide = df_time_wide.rename (columns = {{\n",
    "'current_xyats': 'Time_tea',\n",
    "'Previous_xyats': 'Time_ predecessor',\n",
    "'Perebusky_xyan': 'Time_novable'\n",
   "execution_count": null
    "# Tables Association\n",
    "df_full = df_main.merge (df_revenue_wide, on = 'id', how = 'left')\n",
    "df_full = df_full.merge (df_time_wide, on = 'id', how = 'left')\n",
    "# Let's check the size\n",
    "Print (F'DAMMENT of the United Table: {DF_FULL.SHApe [0] rows')\n"
   "outputs": [],
   "execution_count": null
    "### histograms and boxplot’s on numerical characteristics, for categorical signs - column diagrams for groups\n"
   ],
   "outputs": [],
   "execution_count": null
    "# Divide the data into groups\n",
    "df_active = df_full [df_full ['customer activity'] == 'previous level']\n",
    "df_dropped = df_full [df_full ['purchasing activity'] == 'decreased']\n"
   "execution_count": null
    "# Compare the numerical signs\n",
    "# List of numerical signs without ID\n",
    "num_cols = df_full.select_dtypes (include = ['int64', 'float64']). Drop (columns = 'id'). Columns).\n",
    "\n",
    "# Build the cashed histograms\n",
    "Cols = 3\n",
    "rows = (Len (num_cols) + cols - 1) // Cols\n",
    "PLT.Figure (figsize = (5 * cols, 4 * rows))\n",
    "\n",
    "for i, color in enumerate (num_cols):\n",
    "PLT.SUBPLOT (Rows, Cols, I + 1)\n",
    "PLT.HIST (df_active [color], bins = 20, alpha = 0.6, label = 'previous level')\n",
    "PLT.HIST (df_Dropped [color], bins = 20, alpha = 0.6, label = 'decreased')\n",
    "plt.title (color)\n",
    "PLT.LEGEND ()\n",
    "\n",
    "plt.tight_layout ()\n",
    "PLT.SUPTITLE ('Distribution of numerical features by the target feature', y = 1.02, fontsize = 16)\n",
    "PLT.SHOW ()\n"
   "outputs": [],
   "execution_count": null
    "# Categorical signs\n",
    "Col = 'Popular_ Kategoria'\n",
    "CTAB = PD.crosstab (df_full [color], df_full ['purchasing activity'], normalize = 'index')\n",
    "\n",
    "Ctab.plot (kind = 'barh', stacked = true, figsize = (8, 6)) # horizontal diagram\n",
    "plt.title (f '{color} by activity groups')\n",
    "PLT.XLABEL ('share')\n",
    "PLT.YLABEL ('Category')\n",
    "PLT.GRID (Axis = 'X')\n",
    "plt.tight_layout ()\n",
    "PLT.SHOW ()\n"
   "outputs": [],
   "execution_count": null
    "# Horizontal graph for 'Type Service'\n",
    "Col = 'Type of Service'\n",
    "CTAB = PD.crosstab (df_full [color], df_full ['purchasing activity'], normalize = 'index')\n",
    "\n",
    "Ctab.plot (kind = 'barh', stacked = true, figsize = (6, 3)) # horizontal diagram\n",
    "plt.title (f '{color} by activity groups')\n",
    "PLT.XLABEL ('share')\n",
    "PLT.YLABEL ('Type of Service')\n",
    "PLT.GRID (Axis = 'X')\n",
    "plt.tight_layout ()\n",
    "PLT.SHOW ()\n"
   "outputs": [],
   "execution_count": null
    "### conclusion by step 4: Table association\n",
    "- the `market_money.csv` table is converted from a long format into wide, with columns:` revenue_tek`, `revenue_field`,` revenue_do_ this.\n",
    "- the `market_time.csv` table is transformed similarly to the columns:` Time_te`, `Time_field`.A sign of `time_d_e is absent in the source data.\n",
    "- All transformed tables are combined with the main (`market_file.csv`) by the key` id`.The size of the final table: 1300 lines and 18 signs.\n",
    "- The profit table (`money.csv`) contains unique` id`, completely coinciding with the main table, and will be used later at the segmentation stage.\n",
    "Based on a visual analysis of distributions, one can distinguish the features of customer behavior whose purchasing activity has decreased:\n",
    "- ** communications: ** less often agree to mailings, receive less marketing touches.\n",
    "- ** User behavior: ** Viewing fewer pages and categories, spend less time on the site.\n",
    "- ** Promotions and purchases: ** Make fewer promotional purchases, less goods are left in the basket.\n",
    "- ** financial indicators: ** they have below revenue in each of the three months.\n",
    "- ** Categories of interests: ** more often buy cosmetics and dishes;Less commonly - goods for children and equipment.\n",
    "- ** Type of service: ** Among them, the tariff `standard` is more common.\n",
    "Thus, customers with reduced activity demonstrate signs of reducing involvement and less loyalty to the store.These behavioral features can be used to build a model and subsequent segmentation.\n"
   ],
   "outputs": [],
   "execution_count": null
    "# Preparation of signs and target column\n",
    "# The target feature\n",
    "df_full ['purchasing activity'] = df_full ['purchasing activity']. Map ({{\n",
    "'Decreased': 1,\n",
    "'Previous level': 0\n",
    "# Targeted variable and signs\n",
    "Target = 'Business activity'\n",
    "X = df_full.drop (columns = [target])\n",
    "y = df_full [target]\n",
    "# List of Signs\n",
    "cat_features = ['Type of service', 'Popular_Categoria']\n",
    "num_features = [color for color in x.columns if color not in ['id'] + cat_features]\n",
    "# Separation into training and test samples\n",
    "X_TRAIN, X_TEST, Y_TRAIN, Y_TEST = TraIN_TEST_SPLIT (\n",
    "X, y, test_size = 0.25, stratify = y, random_state = 42\n",
   "execution_count": null
    "# Categorical and numerical features\n",
    "cat_features = df_main.select_dtypes (include = 'object'). Drop (Columns = 'Consumitarian Activity'). Columns.tolist ()\n",
    "num_features = df_main.select_dtypes (include = ['int64', 'float64']). Drop (columns = 'id'). Columns.tolist ()\n",
    "\n",
    "# Categorical transformer\n",
    "Cat_transformer = pipeline (stps = [\n",
    "('imputer', simpleimputer (strategy = 'most_frequent')),\n",
    "('Onehot', Onehotencoder (drop = 'first'))\n",
    "# Numerical transformers\n",
    "num_transformer_standard = pipeline (stps = [\n",
    "('imputer', simpleimputer (strategy = 'median')),\n",
    "('Scaler', StandardScaler ())\n",
    "num_transformer_minmax = pipeline (stps = [\n",
    "('imputer', simpleimputer (strategy = 'median')),\n",
    "('scaler', minmaxscaler ())\n",
    "# Two Preprocessor options\n",
    "PreProcessor_OPTIONS = {{\n",
    "'Standard': Columntransformer ([\n",
    "('num', num_transformer_standard, num_features),\n",
    "('cat', cat_transformer, cat_features)\n",
    "])\n",
    "'minmax': columntransformer ([\n",
    "('num', num_transformer_minmax, num_features),\n",
    "('cat', cat_transformer, cat_features)\n",
    "])\n",
    "# Dictionary of models with hyperparameters, including a preprocessor\n",
    "'Logisticregression': {\n",
    "'Model': Logisticregression (max_iter = 1000),\n",
    "'params': {\n",
    "'PREPROCESSOR': [PreProcessor_OPTIONS ['Standard'], PREPROCESSOR_OPTIONS ['minmax']],\n",
    "'Model__c': [0.01, 0.1, 1, 5, 10]\n",
    "}\n",
    "}\n",
    "'Decisiontree': {\n",
    "'Model': decisiontreeclassifier (random_state = 42),\n",
    "'params': {\n",
    "'PREPROCESSOR': [PreProcessor_OPTIONS ['Standard'], PREPROCESSOR_OPTIONS ['minmax']],\n",
    "'model__max_depth': [3, 5, 8, 10, 15],\n",
    "'model__min_samples_split': [2, 4, 5, 10]\n",
    "}\n",
    "}\n",
    "'Kneighbors': {\n",
    "'Model': Kneighborsclassifier (),\n",
    "'params': {\n",
    "'PREPROCESSOR': [PreProcessor_OPTIONS ['Standard'], PREPROCESSOR_OPTIONS ['minmax']],\n",
    "'model__n_neighbors': [3, 5, 7, 9],\n",
    "'Model__weights': ['Uniform', 'Distance']\n",
    "}\n",
    "}\n",
    "'Svc': {\n",
    "'Model': SVC (Probability = True),\n",
    "'params': {\n",
    "'PREPROCESSOR': [PreProcessor_OPTIONS ['Standard'], PREPROCESSOR_OPTIONS ['minmax']],\n",
    "'Model__c': [0.1, 1, 10],\n",
    "'Model__kernel': ['linear', 'rbf']\n",
    "}\n",
    "}\n",
   "execution_count": null
    "Best_Models = {}\n",
    "\n",
    "for name, item in models.items ():\n",
    "Print (f \"\\ n ====== Search by model: {name} ======\")\n",
    "\n",
    "# We collect a common pickle with a preprocessor player\n",
    "pipe = pipeline (stps = [\n",
    "('PreProcessor', 'Passthrough'), # will be replaced by Gridsearch'em\n",
    "('model', item ['model'])\n",
    "])\n",
    "\n",
    "# RANDOMIZEDSEARCHCV\n",
    "Search = RandomizedSearchcv (\n",
    "PIPE,\n",
    "item ['params'],\n",
    "scoring = 'roc_auc',\n",
    "CV = 5,\n",
    "n_iter = 10,\n",
    "random_state = 42,\n",
    "n_jobs = -1\n",
    ")\n",
    "\n",
    "# Education\n",
    "search.fit (x_train, y_train)\n",
    "y_pred_Proba = search.predict_Proba (x_test) [:, 1]\n",
    "score = roc_auc_score (y_test, y_pred_proba)\n",
    "Print (F \"ROC AUC: {Score: .4f}\")\n",
    "\n",
    "# Save the result\n",
    "Best_Models [name] = {{\n",
    "'Model': search.best_estimator_,\n",
    "'score': score\n",
    "}\n"
   "outputs": [],
   "execution_count": null
    "### conclusion in step 6: Building models\n",
    "\n",
    "- Four models were trained (`LogisticregResion`,` Decisiontree`, `Kneighbors`,` SVC`) using the fees and the selection of hyperparameters via `randomizedSearchcv`.\n",
    "- RoC AUC was used as the main metric, since the task is a binary classification with a moderate class imbalance.\n",
    "- For all models, two options for scaling signs were tested: `Standardscler` and` MinmaxScaler ', as required by the task.\n",
    "- The best performance was shown by the `SVC` model, reaching ROC AUC = ** 0.9019 **.\n",
    "- High results also showed:\n",
    "- `LogisticregResion` - ROC AUC = ** 0.9012 **\n",
    "- `kneighborsclassifier` - ROC AUC = ** 0.8876 **\n",
    "- Model `decisiontree` showed the smallest efficiency - ROC AUC = ** 0.8729 **.\n",
    "- For further analysis of the importance of the signs and interpretation of the model, ** model `svc` **, as showing the best quality of classification, will be used.\n"
   ],
   "outputs": [],
   "execution_count": null
    "# Interpretation of the model\n"
   ],
   "outputs": [],
   "execution_count": null
    "# Find a model with the highest ROC AUC\n",
    "Best_key = max (Best_models, Key = lambda k: Best_Models [k] ['score'])\n",
    "Best_Model = Best_Models [Best_key] ['Model']\n",
    "Print (F'Best Model: {Best_key} C Roc Auc = {Best_models [Best_key] [\"Score\"] :. 4F} ')\n",
    "# Extract a preprocessor and model from a feather\n",
    "PreProcessor = Best_Model.named_steps ['Preprocessor']\n",
    "model = best_model.named_steps ['model']\n",
    "Print (PreProcessor.transformers [0] [1] .named_steps ['Scaler'])\n"
   "outputs": [],
   "execution_count": null
    "# Let's convert a training sample\n",
    "X_TRAIN_TRANSFORMED = PREPROCESSOR.TRANSFORM (X_TRAIN)\n",
    "# We get the names of categorical signs (Onehotencoder with Drop = 'FIRST')\n",
    "ohe = preprocessor.named_transformers _ ['cat']. Named_steps ['Onehot']\n",
    "ohe_feature_names = ohe.get_feature_names_ut (cat_features)\n",
    "# Combine with numerical\n",
    "all_Feature_names = list (ohe_feature_names) + num_features\n"
   "execution_count": null
    "# Find the best LogisticregRESSON on Score\n",
    "log_keys = [k for k in best_models if k.startswith\n",
    "Best_log_key = max (log_keys, key = lambda k: best_models [k] ['score'])\n",
    "log_model = best_models [Best_log_key] ['Model']\n",
    "\n",
    "# We get a preprocessor and trained data\n",
    "PreProcessor = log_model.named_steps ['PreProcessor']\n",
    "model = log_model.named_steps ['model']\n",
    "\n",
    "# Let's convert a training sample\n",
    "X_TRAIN_TRANSFORMED = PREPROCESSOR.TRANSFORM (X_TRAIN)\n",
    "\n",
    "# We get the names of the signs\n",
    "ohe = preprocessor.named_transformers _ ['cat']. Named_steps ['Onehot']\n",
    "ohe_feature_names = ohe.get_feature_names_ut (cat_features)\n",
    "all_feature_names = num_features + list (ohe_feature_names)\n",
    "\n",
    "# Convert the array to Dataframe\n",
    "X_train_df = pd.dataframe (x_train_transformed, columns = all_feature_names)\n",
    "\n",
    "# Shap for Logisticregression\n",
    "Explainer = Shap.explainer (Model, X_TRain_DF)\n",
    "Shap_values ​​= Explainer (x_train_df)\n",
    "\n",
    "# Schedule\n",
    "Shap.summary_plot (\n",
    "Shap_values.values,\n",
    "features = x_train_df,\n",
    "feature_names = all_feature_names,\n",
    "Show = True,\n",
    "PLOT_SIZE = (18, 13)\n",
   "outputs": [],
   "execution_count": null
    "### conclusion in step 7: Model interpretation\n",
    "- The following signs had the greatest impact on the prediction of a decrease in customer activity:\n",
    "- ** `Pages_za_vizit` ** and **` average_ -seam_kategoria_za_zit` ** - users who are more actively studying the site have a lower risk of reducing activity.\n",
    "- ** `unpaid_P products_STUK_Kartal` ** - a large number of abandoned goods in the basket are positively associated with the risk of outflow.\n",
    "- ** `Active_ -purchases` ** - frequent participation in shares - an important factor that shifts the prediction towards the outflow.\n",
    "- ** `Market_activ_6_Mes` ** - the long -term exposure to marketing campaigns is associated with increased risk, especially with high values.\n",
    "- A significant effect is also exerted:\n",
    "- Some ** categorical signs **, especially buyers who prefer the categories of “small household appliances” and “technology for beauty” - they are more likely to apply to customers with reduced loyalty.\n",
    "- ** `Error_Service` ** and **` Duration` ** (in days from the moment of registration) - reflect the customer’s user experience and maturity.\n",
    "- The less significant for the model turned out to be:\n",
    "- ** `Market_activ_Tec_xmes` **, **` Type of service_standart` **, ** `Allocate to report` **, as well as popular categories\" Cosmetics \",\" kitchen dishes \"and\" goods for children \".\n",
    "- ** Conclusion: ** The most informative for the model are the signs that reflect ** the involvement of the client on the site ** and ** his reaction to marketing activity **.These data should be taken into account when segmentation of customers and the formation of personalized deduction strategies.\n"
   ],
   "outputs": [],
   "execution_count": null
    "# Customer segmentation and recommendations\n"
   ],
   "outputs": [],
   "execution_count": null
    "### Step 8: Customer segmentation and recommendations\n",
    "### the goal of segmentation\n",
    "In the previous stages, we studied the behavior of customers who have reduced activity and determined the key features affecting the outflow: low involvement on the site, orientation on stocks, a smaller volume of revenue.\n",
    "Now, on the basis of the model and probabilities of reducing activity, we will single out specific customer groups for further analysis and personalized actions.The task is to determine which segments are most important to retain or require attention from the point of view of marketing.\n",
    "#### Logic selection selection\n",
    "I decided to consider ** three segments **, each of which has business significance:\n",
    "- ** segment a: **\n",
    "Clients with a high probability of reducing activity ** and at the same time ** high profit **.\n",
    "This is a key group for priority retention - the loss of these customers will be the most painful for business.\n",
    "- ** segment b: **\n",
    "Clients with ** high share of promotional purchases ** and ** average profit **.\n",
    "The risk of forming dependence on discounts and, as a result, a decrease in marginality is possible.The segment is important for rethinking marketing strategies.\n",
    "- ** segment C: **\n",
    "Customers buying ** goods for children **, and at the same time having ** increased risk of outflow **.\n",
    "The possible sign that in the “Products for Children” category there are problems with interest/retention, despite the importance of this audience (for example, young families).\n",
    "#### Why are the three segments chosen\n",
    "During segmentation, we do not just share users, but select groups with different business risks and behavioral patterns:\n",
    "- ** The A ** segment covers customers whose loss is the most critical due to high profit.\n",
    "- ** segment b ** allows you to evaluate the effectiveness of marketing and identify customers prone to discounts.\n",
    "- ** The C ** segment is important for analysis of behavior in a particular product category with potential risk.\n",
    "Such a choice covers three different business hypotheses: holding valuable customers, margin management, and adjusting commodity strategies.\n"
   ],
   "outputs": [],
   "execution_count": null
    "# 1. Prediction of the probability of outflow\n",
    "X_all = df_full.drop (columns = ['purchasing activity'])\n",
    "y_all = df_full ['purchasing activity']\n",
    "# We get probabilities from the model (1 - \"decreased\")\n",
    "PROBA = BEST_MODEL.Predict_PROBA (X_ALL) [:, 1]\n",
    "# Save in Dataframe\n",
    "df_segmentation = pd.dataframe ({\n",
    "'id': x_all ['id'],\n",
    "'Probability of_TTOKA': PROBA\n",
    "# 2. We attach profit\n",
    "df_segmentation = df_segmentation.merge (df_profit, on = 'id', how = 'left')\n",
    "# 3. Add the necessary signs from df_full\n",
    "df_segmentation = df_segmentation.merge (\n",
    "df_full ['id', 'promotional_ -purchases', 'Popular_ -Kategoria']],\n",
    "on = 'id',\n",
    "How = 'Left'\n",
    "# Let's see the result\n",
    "Display (df_segmentation.head ())\n"
   "outputs": [],
   "execution_count": null
    "# Segment A: High profit and high risk of outflow\n",
    "segment_a = df_segmentation [\n",
    "(df_segmentation ['probability of_totka']> 0.7) &\n",
    "(df_segmentation ['profit']> 4.0)\n",
    "# Segment B: High share of promotional purchases and average profits\n",
    "segment_b = df_segmentation [\n",
    "(df_segmentation ['promotional_ -purchases']> 0.7) &\n",
    "(df_segmentation ['profit']. Between (2.0, 4.0))\n",
    "# Segment C: buyers of goods for children with risk of outflow\n",
    "segment_c = df_segmentation [\n",
    "(df_segmentation ['Popular_Category'] == 'Products for children') &\n",
    "(df_segmentation ['probability of_totka']> 0.5)\n",
    "# Let's check the dimensions\n",
    "Print (F'Segment a: {segment_a.shape [0] clients')\n",
    "Print (F'Segment b: {segment_b.shape [0] clients')\n",
    "Print (F'Segment C: {segment_c.shape [0] clients')\n"
   "outputs": [],
   "execution_count": null
    "### 12.7.4 Conclusion by step 8: Customer segmentation and recommendations\n",
    "Based on the predicted probabilities of outflow and business signs, three key segments were allocated:\n",
    "- ** segment A ** - 185 clients with high profit and at the same time high risk of outflow.\n",
    "Critically important for retention: priority No. 1.\n",
    "- ** segment b ** - 80 clients with a high share of promotional purchases and average profit.\n",
    "Demand rethinking marketing approaches: unprofitability risk.\n",
    "- ** segment C ** - 132 clients buying goods for children, with an increased risk of outflow.\n",
    "Possible problems in holding the target category: It is important to check the user path and commodity supply.\n",
    "The segments do not intersect and reflect three different business bolt.\n",
    "The result of the segmentation was the construction of a focus for subsequent actions: retention, correction of marketing and analysis of problematic product areas.\n"
   ],
   "outputs": [],
   "execution_count": null
    "# 1. Visualization of distributions\n",
    "PLT.Figure (figsize = (12, 8))\n",
    "\n",
    "PLT.SUBPLOT (2, 2, 1)\n",
    "PLT.Hist (segment_a ['profit'], bins = 10, edgecolor = 'Black')\n",
    "plt.title ('profit (segment a)')\n",
    "\n",
    "PLT.SUBPLOT (2, 2, 2)\n",
    "PLT.HIST (segment_a ['probability of_do'], bins = 10, edgecolor = 'Black')\n",
    "plt.title ('probability of outflow (segment a)')\n",
    "\n",
    "PLT.SUBPLOT (2, 2, 3)\n",
    "PLT.HIST (segment_a ['promotional_ -purchases'], bins = 10, edgecolor = 'Black')\n",
    "plt.title ('share of promotional purchases (segment a)')\n",
    "\n",
    "PLT.SUBPLOT (2, 2, 4)\n",
    "segment_a ['Popular_Category']. Value_counts (). Plot (kind = 'bar')\n",
    "PLT.Title ('Popular categories (segment A)')\n",
    "PLT.XTICS (Rotation = 45)\n",
    "\n",
    "plt.tight_layout ()\n",
    "PLT.SHOW ()\n",
    "\n",
    "# 2. Consolidated characteristics\n",
    "Print (\"Average profit:\", Round (segment_a ['profit']. Mean (), 2))\n",
    "Print (\"The average probability of outflow:\", round (segment_a ['probability of_tota']. Mean (), 2))\n",
    "Print (\"Average share of promotional purchases:\", Round (segment_a ['promotional_ -purchases']. Mean (), 2))\n",
    "Print (\"\\ nkategoria of goods:\")\n",
    "Print (segment_a ['Popular_Category']. Value_counts ())\n"
   "outputs": [],
   "execution_count": null
   "outputs": [],
   "execution_count": null
    "# 1. Add to each segment data on revenue from df_full\n",
    "Cols_to_add = ['id', 'Popular_Acategory', 'revenue_ -reimbursable', 'revenue_ predecessor', 'revenue_tea']\n",
    "\n",
    "segment_a_ext = segment_a.merge (df_full [colors_to_add], on = ['id', 'popular_category'], but = 'left')\n",
    "segment_b_ext = segment_b.merge (df_full [colors_to_add], on = ['id', 'popular_category'], how = 'left')\n",
    "segment_c_ext = segment_c.merge (df_full [colors_to_add], on = ['id', 'popular_category'], how = 'left')\n",
    "\n",
    "# 2. We calculate the delta\n",
    "for df in [segment_a_ext, segment_b_ext, segment_c_ext]:\n",
    "df ['textual'] = df ['revenue_ -flowing'] - df ['revenue_ predecessor']\n",
    "df ['foresee'] = df ['revenue_ predecessor'] - df ['revenue_ -reimbursable']\n",
    "\n",
    "# 3. Function: conclusion and visualization\n",
    "Def Revenue_dynamics_summary_with_plot (df_segment, name):\n",
    "Summary = df_segment.groupby ('Popular_stagoria') [['Text -subject', 'Preferent']]. mean (). Round (2)\n",
    "Print (f \"\\ n {name}: the average dynamics of revenue by categories\")\n",
    "Display (Summary)\n",
    "\n",
    "# Visualization\n",
    "AX = Summary.plot (Kind = 'Bar', Figsize = (10, 5), Edgecolor = 'Black')\n",
    "PLT.Title (F' -medium dynamics of revenue by categories - {name} ')\n",
    "PLT.XLABEL ('Category')\n",
    "PLT.YLABEL ('average change in revenue')\n",
    "PLT.AXHLINE (0, color = 'Gray', linestyle = '-')\n",
    "PLT.XTICS (Rotation = 45)\n",
    "PLT.GRID (Axis = 'Y')\n",
    "plt.tight_layout ()\n",
    "PLT.SHOW ()\n",
    "\n",
    "# 4. We apply to each segment\n",
    "Revenue_dynamics_summary_with_plot (segment_a_ext, \"segment a\")\n",
    "Revenue_dynamics_summary_with_plot (segment_b_ext, \"segment b\")\n",
    "Revenue_dynamics_summary_with_plot (segment_c_ext, \"segment C\")\n"
   "outputs": [],
   "execution_count": null
    "### conclusion by step 8: Customer segmentation and recommendations\n",
    "\n",
    "** Selected segment: **\n",
    "The analysis was carried out for ** segment A ** - customers with high profit (> 4.0) and a high probability of outflow (> 0.7).This segment includes ** 186 users **, which is more than 12% of the entire base and gives the greatest contribution to the revenue.\n",
    "\n",
    "** Dynamics of revenue: **\n",
    "- The largest revenue growth in the last month is observed in the categories ** “Cosmetics and accessories” **, ** “kitchen dishes” ** and ** “home textiles” **.\n",
    "- The outflow of revenue in the penultimate month was marked in ** “technique for beauty” ** and ** “products for children” **, which signals a possible reduction in interest in these categories.\n",
    "- Despite the growth in the current month, ** “Products for children” ** show weak stability - the revenue fluctuates on them.\n",
    "\n",
    "** The proposed measures: **\n",
    "- Configure personalized newsletters with content in your favorite categories.\n",
    "- divide customers into subgroups in sensitivity to shares:\n",
    "- one - to offer benefits without shares,\n",
    "- To others - use discounts, bonuses, cashback.\n",
    "- Add privileges for the most profitable customers: priority support, managerial line, early access to new products.\n",
    "\n",
    "** Business renewal: **\n",
    "- The loss of a client from this segment can lead to ** loss of 4-7 units of profit **.\n",
    "- Holding even ** 10% of customers ** from the segment can significantly increase ** LTV ** and reduce ** CAC **.\n",
    "- Clients of the segment have pronounced preferences, which facilitates targeting and personalization.\n",
    "\n",
    "**Conclusion:**\n",
    "The segment A requires priority attention: due to high profits, significant outflow and potential to retain.A personalized approach and optimization of proposals will save customers and increase their value for business.\n"
   ],
   "outputs": [],
   "execution_count": null
    "### General conclusion on the project\n",
    "#### Task\n",
    "The online store “In one click” set the task-to predict the likelihood of ** reducing the purchasing activity of regular customers ** to determine ** risk groups ** and offer ** personalized retention measures **.\n",
    "#### Data and Sources\n",
    "Four tables were provided:\n",
    "- `market_file.csv` - marketing, behavioral and categorical features.\n",
    "- `market_money.csv` - monthly revenue.\n",
    "- `market_time.csv` - the time spent on the site.\n",
    "- `money.csv` - the final profit from the client.\n",
    "#### data exposure\n",
    "- fixed typos in categorical features and names of periods.\n",
    "- Duplicates and gaps are checked and cleaned.\n",
    "- 3 clients with zero revenue in one of the months are excluded.\n",
    "- One extreme ejection on revenue is filtered.\n",
    "- The tables are combined by `ID`, the final dataset contains ** 1297 lines ** and ** 18 signs **.\n",
    "#### Research Analysis (EDA)\n",
    "- Clients with reduced activity more often:\n",
    "- less often agree to mailings,\n",
    "- spend less time on the site,\n",
    "- do less views and purchases,\n",
    "- stronger depends on shares,\n",
    "- They bring less revenue.\n",
    "- Correlations confirm: involvement (time, views, pages) reduces the risk of outflow.\n",
    "- Signs with the largest number of emissions: marketing activity and promotional purchases.\n",
    "- Signs are left as potentially informative for the model.\n",
    "### Model Training\n",
    "- 4 models are trained (`logisticregression`,` decisiontree`, `kneighbors`,` svc`) with two scaling methods (`standardscaler`,` minmaxscaler`).\n",
    "- Used by `RandomizedSearchcv`, metric - ** roc auc **.\n",
    "- ** The best model: ** `svc` with` minmaxscler`, roc auc = ** 0.9019 **.\n",
    "- High results also showed:\n",
    "- `LogisticregResion` - ROC AUC = ** 0.9012 **\n",
    "- `kneighborsclassifier` - ROC AUC = ** 0.8876 **\n",
    "#### interpretation of the model\n",
    "- For interpretation, `LogisticregResion` (transparent model) was used.\n",
    "- Shap indicators revealed that the most impact on the outflow has:\n",
    "- `Pages_za_vizit`,` average_ -examination_kategoria_za_vizit` - indicators of involvement.\n",
    "- `unpaid_products_Tuk_Cartal` and` promotional_ -purchases` - abandoned baskets and sensitivity to discounts.\n",
    "- `Market_activ_6_Mes` and old revenues - traces of fatigue from communications.\n",
    "#### Customer segmentation\n",
    "Based on the probability of outflow, profit and behavioral signs, ** three segments **:\n",
    "- ** segment A ** - 185 clients: high profit (> 4.0) and high risk of outflow (> 0.7).\n",
    "- * average profit: * 4.76\n",
    "- * The average probability of outflow: * 0.95\n",
    "- * Popular categories: * \"Products for children\", \"Cosmetics\", \"Home textile\"\n",
    "- * negative dynamics: * in the category \"Technique for Beauty\"\n",
    "- ** segment b ** - 80 clients: high share of promotional purchases (> 0.7), average profit (2–4).\n",
    "- Possible risk of discount dependence.\n",
    "- The fall in revenue in a number of categories has been noticed, especially \"goods for children\"\n",
    "- ** segment C ** - 132 clients: Buyers of the category of \"goods for children\" with an increased risk of outflow (> 0.5).\n",
    "- unstable revenue, problems in the category: outdated assortment, ux, seasonality are possible\n",
    "#### Dynamics of revenue\n",
    "- In the segment a:\n",
    "- the greatest decline in \"Technique for Beauty\" (the previous month is a sharp decrease).\n",
    "- In the segment b:\n",
    "- Negative dynamics in “Products for children” and partially in “Technique”.\n",
    "- In the segment C:\n",
    "- “Products for children” - weak stability, negative dynamics in the penultimate month.\n",
    "#### business recommendations\n",
    "** segment A ** - Priority retention:\n",
    "- personalize marketing in your favorite categories.\n",
    "- Add bonus programs, priority support, exclusive offers.\n",
    "- Do not use discounts - holding the price of service and privileges.\n",
    "** segment b ** - control of discount dependence:\n",
    "- Conduct A/B tests to reduce the number of shares.\n",
    "- Introduce alternative mechanics: cashback, cumulative points, privileges for loyalty.\n",
    "** segment C ** - Analysis of the product category:\n",
    "- Conduct UX assessment and study of usability on the site.\n",
    "- To double -check the assortment and seasonality in “Products for children”.\n",
    "- Collect feedback - find out what is the reason for a decrease in interest.\n"
   ],
   "outputs": [],
   "execution_count": null
    "### comment on the recommendations:\n",
    "Segment A - priority retention\n",
    "Why is it highlighted:\n",
    "These are customers with high profit and high probability of outflow.Their loss will be the most painful for business, so the retention of this group is the main priority.\n",
    "Recommendations:\n",
    "Personalized proposals:\n",
    "Supporting interest in purchases through targeted campaigns in your favorite categories (“goods for children”, “cosmetics”, etc.) - to increase involvement without reducing prices.\n",
    "Bonus programs / Priority service:\n",
    "Since the segment is loyal and brings profit, it is logical to strengthen emotional binding through intangible advantages - for example, priority in delivery, access to new collections, and the allocated manager.\n",
    "Do not use discounts:\n",
    "These clients are already buying at the “full price”, and are not prone to promotional offers - discounts will be ineffective and reduce the margin.\n",
    "Segment b - control of discount dependence\n",
    "Why is it highlighted:\n",
    "These clients make a lot of purchases for shares, while bringing not the highest profit.There is a risk that they are used to discounts and do not buy without them.\n",
    "Recommendations:\n",
    "A/b test to restrict discounts:\n",
    "Check how such customers will react to the lack of shares.Perhaps they will continue to buy without discounts, and then it will be possible to improve margin.\n",
    "Transition to other benefits:\n",
    "Instead of constant discounts - bonuses, accumulative systems, or suggestions on recommendations.This reduces the dependence on the promo and teaches the client to another type of value.\n",
    "Segment C-commodity and ux analysis\n",
    "Why is it highlighted:\n",
    "These clients have the main interest - the category of \"goods for children.\"At the same time, they demonstrate a high risk of outflow.The analysis showed the negative dynamics of revenue in this category.\n",
    "Recommendations:\n",
    "Checking a product assortment:\n",
    "There is a chance that the product is out of place, it does not correspond to expectations, or it got worse.This requires a review.\n",
    "Feedback collection:\n",
    "It is recommended to conduct a small study among this group to find out the causes of care.\n",
    "Analysis UX and windows:\n",
    "Perhaps problems are not in goods, but in their view: filters, description, photo, positioning.This is also worth checking before investments in the purchase.\n"
   ],
   "outputs": [],
   "execution_count": null
}